# ğŸ©º AI Wound Classification & Medical RAG System

An end-to-end **Flask-based AI application** that:
- Classifies wound images using a **CNN (TensorFlow)**
- Provides **medical guidance** using **RAG (Retrieval-Augmented Generation)** with a local LLM

Designed for **exam, viva, and technical interviews**.

---

## ğŸ”¹ System Architecture (Diagrammatic)

User (Browser)
â”œâ”€â”€ Upload Image / Image URL
â””â”€â”€ Ask Medical Question
â†“
Flask Application (app.py)
â”œâ”€â”€ CNN Model (TensorFlow)
â”‚ â†“
â”‚ Wound Classification
â”‚
â””â”€â”€ RAG Pipeline (LangChain)
â†“
Chroma Vector Database
â†“
Ollama LLM (LlamaMedicine)
â†“
Medical Guidance

---

## ğŸ”¹ Supported Wound Classes

Abrasions
Bruises
Burns
Cut
Ingrown_nails
Laceration
Stab_wound
Healthy

---

## ğŸ”¹ Technology Stack

| Layer | Technology |
|-----|-----------|
| Backend | Flask |
| ML Model | TensorFlow (CNN) |
| RAG Framework | LangChain |
| Vector DB | Chroma |
| LLM | Ollama (Elixpo/LlamaMedicine) |
| Embeddings | nomic-embed-text |
| Frontend | HTML (Jinja Templates) |

---

## ğŸ”¹ Project Structure

.
â”œâ”€â”€ app.py # Main Flask app
â”œâ”€â”€ wound_classifier_final.keras # Trained CNN model
â”œâ”€â”€ class_names.json # Wound labels
â”œâ”€â”€ uploads/ # Uploaded images
â”œâ”€â”€ medical_knowledge_db/ # Medical PDFs
â”œâ”€â”€ chroma_db/ # Vector store
â”œâ”€â”€ templates/
â”‚ â””â”€â”€ index.html # UI
â””â”€â”€ README.md

---

## ğŸ”¹ Working Explained

### Image Classification Flow

Input Image
â†“
Resize (224 Ã— 224)
â†“
CNN Model
â†“
Softmax Layer
â†“
Predicted Wound Type

---

### Medical RAG Flow

User Question
â†“
Text Embedding
â†“
Chroma Similarity Search
â†“
Relevant PDF Context
â†“
Ollama LLM
â†“
Context-Based Medical Answer

---

## ğŸ”¹ Why RAG Instead of Plain LLM?

- Prevents hallucinations
- Answers only from **trusted medical PDFs**
- Safer for healthcare-related use cases
- Strong architectural choice for interviews

---

## ğŸ”¹ Setup & Run

### 1. Install Dependencies
```bash
pip install -r requirements.txt
2. Start Ollama
ollama run Elixpo/LlamaMedicine
3. Run Application
python app.py
4. Open in Browser
http://127.0.0.1:5000
ğŸ”¹ Key Interview Points
CNN handles visual understanding
RAG handles knowledge grounding
Chroma enables semantic search
Ollama allows local, private LLM inference
Clean separation of ML and NLP pipelines
ğŸ”¹ Future Enhancements
Confidence score visualization
Multilingual medical responses
Mobile-first UI
Doctor-verified response layer
âš ï¸ Disclaimer
This project is for educational purposes only.
It is not a substitute for professional medical advice.

---

If you want next:
- ğŸ”¹ **One-page viva notes**
- ğŸ”¹ **System design explanation (2â€“3 min answer)**
- ğŸ”¹ **Interview Q&A from this project**

Just say the word.
